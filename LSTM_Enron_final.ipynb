{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vin-thomas/Enron_email_classification/blob/main/LSTM_Enron_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUx4E-r0DBvl"
      },
      "source": [
        "**1.0 Import**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "353aMfJgCAxO",
        "outputId": "e1431a7c-2b07-4e15-8c08-2e2f5691b751"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "import torch\n",
        "import glob\n",
        "from nltk.tokenize import word_tokenize\n",
        "import torch.nn.functional as F\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YuNpjeUIqRNv",
        "outputId": "d30fe55e-49a9-45a2-962e-1599a9785777"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7YY45P7WJ61J"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/AIML Labs/@Project/working files 2b/Pre_processed/enron_csv_1', index_col=[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XKwQO-IcKF_-"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "add_fm = []\n",
        "add_to = []\n",
        "add_cc = []\n",
        "add_bcc = []\n",
        "for item in df.Raw_Text:\n",
        "  fm_emails = re.findall(r\"From: ([a-z0-9\\.\\-+_]+@[a-z0-9\\.\\-+_]+\\.[a-z]+)\", str(item))\n",
        "  to_emails = re.findall(r\"To: ([a-z0-9\\.\\-+_]+@[a-z0-9\\.\\-+_]+\\.[a-z]+)\", str(item))\n",
        "  cc_emails = re.findall(r\"Cc: ([a-z0-9\\.\\-+_]+@[a-z0-9\\.\\-+_]+\\.[a-z]+)\", str(item))\n",
        "  bcc_emails = re.findall(r\"Bcc: ([a-z0-9\\.\\-+_]+@[a-z0-9\\.\\-+_]+\\.[a-z]+)\", str(item))\n",
        "  if fm_emails:\n",
        "    add_fm.append(fm_emails[0])\n",
        "  else:\n",
        "    add_fm.append(1000)\n",
        "  if to_emails:\n",
        "    add_to.append(to_emails[0])\n",
        "  else:\n",
        "    add_to.append(1000)\n",
        "  if cc_emails:\n",
        "    add_cc.append(cc_emails[0])\n",
        "  else:\n",
        "    add_cc.append(1000)\n",
        "  if bcc_emails:\n",
        "    add_bcc.append(bcc_emails[0])\n",
        "  else:\n",
        "    add_bcc.append(1000)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XFJHUFcJKY2-"
      },
      "outputs": [],
      "source": [
        "df['From']= add_fm\n",
        "df['To']= add_to\n",
        "df['CC']= add_cc\n",
        "df['BCC']= add_bcc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t3Kd2hR3Kbtz"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "def preprocess_date(date):\n",
        "  format_data = \"%a, %d %b %Y\"\n",
        "  date = datetime.strptime(date, format_data)\n",
        "  return date"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hOEHOkfUKe33"
      },
      "outputs": [],
      "source": [
        "date_email =[]\n",
        "\n",
        "for item in df.Raw_Text:\n",
        "  date = re.findall(r\"Date: ([a-zA-Z]{3}, \\d+ [a-zA-Z]{3} \\d{4})\", str(item))\n",
        "  date= preprocess_date(date[0])\n",
        "  date_email.append(date)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s4kZCJXUKhj7"
      },
      "outputs": [],
      "source": [
        "df['date']= date_email"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJ4eQZKjKlIj"
      },
      "source": [
        "##**Extracting Subject**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SWunb42yNU8c"
      },
      "outputs": [],
      "source": [
        "item_list = []\n",
        "for item in df.Raw_Text:\n",
        "  item = re.sub(r'[a-z0-9\\.\\-+_]+@[a-z0-9\\.\\-+_]+\\.[a-z]+', '', item)\n",
        "  item_list.append(item)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHuvlBWRpocG",
        "outputId": "cbfb3011-a59e-40fb-f5da-8beccd3243c0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "517401"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "len(item_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L12ovRSQKkPp"
      },
      "outputs": [],
      "source": [
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    text = re.sub(r'\\\\', '', text)\n",
        "    text = re.sub(r'\\\\n', '', text)\n",
        "    text = re.sub(r'-', '', text)\n",
        "    text = re.sub(r'=', '', text)\n",
        "    text = re.sub(r'/', '', text)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hb1iR8s1Kt94"
      },
      "outputs": [],
      "source": [
        "subject_email = []\n",
        "\n",
        "for item in item_list:\n",
        "  subject = re.findall(r\"Subject: ([^\\\\]*)\", str(item))\n",
        "  subject = preprocess_text(subject[0])\n",
        "  word_list = subject.split(' ')\n",
        "  if len(word_list)>10:\n",
        "    word_list = word_list[:10]\n",
        "  subject = \" \".join(word_list)\n",
        "  subject_email.append(subject)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xQjUjaszKwy_"
      },
      "outputs": [],
      "source": [
        "df['Subject']= subject_email"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KiEnuj8jK2kU"
      },
      "source": [
        "##**Extracting Body**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "768ePDK5K4zi"
      },
      "outputs": [],
      "source": [
        "body_email =[]\n",
        "for item in item_list:\n",
        "  body = re.findall (r\"FileName:([\\s\\S]*)$\", str(item))\n",
        "  body = preprocess_text(body[0])\n",
        "  word_list = body.split(' ')\n",
        "  if len(word_list)>90:\n",
        "    word_list = word_list[1:70]\n",
        "  word_list = \" \".join(word_list)\n",
        "  body_email.append(word_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CkRk08tCr4OM"
      },
      "outputs": [],
      "source": [
        "df['Body']= body_email"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dyW7laByK8LK"
      },
      "outputs": [],
      "source": [
        "df_final = df.drop(['Raw_Text'], axis=1)\n",
        "df_final= df_final.drop_duplicates(subset=['Body', 'From'])\n",
        "df_final = df_final[df_final.Folder != 'all_documents']\n",
        "df_final = df_final[df_final.Folder != 'deleted_items']\n",
        "df_final = df_final[df_final.Body != 'na']\n",
        "df_final['Text']= df_final['Body']+' '+ df_final['Subject']\n",
        "df_final.drop(['Subject', 'Body'], axis=1, inplace= True)\n",
        "df_final['from_id']= df_final['From'].factorize()[0]\n",
        "df_final['to_id']= df_final['To'].factorize()[0]\n",
        "df_final['cc_id']= df_final['CC'].factorize()[0]\n",
        "df_final['bcc_id']= df_final['BCC'].factorize()[0]\n",
        "df_final['folder']= df_final['Folder'].factorize()[0]\n",
        "df_final['name']= df_final['Name'].factorize()[0]\n",
        "df_final.drop(['Name', 'Folder', 'From', 'To', 'CC', 'BCC', 'date'], axis=1, inplace= True)\n",
        "df_lstm= df_final\n",
        "df_lstm= df_lstm.reset_index(drop=True)\n",
        "\n",
        "df_lstm = df_lstm[[\"Text\", \"from_id\", \"to_id\", \"cc_id\", \"bcc_id\", \"name\", \"folder\"]]\n",
        "df_addl = df_lstm[['name', 'from_id', 'to_id', 'cc_id', 'bcc_id']]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()  \n",
        "\n",
        "df_addl = scaler.fit_transform(df_addl)"
      ],
      "metadata": {
        "id": "POp4A2peuOuP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_addl.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8lI1F8Dy4bV",
        "outputId": "c4835e0e-eebe-48d5-c572-c3ac90148884"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(204850, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a25aBFlHpvrg",
        "outputId": "c5fd94ec-d2f6-4e1c-8eaa-c56f8e1094cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text       204678\n",
            "from_id     15295\n",
            "to_id       16054\n",
            "cc_id        7095\n",
            "bcc_id       6972\n",
            "name          225\n",
            "folder       1328\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(df_lstm.nunique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g8M_jmQRLoma"
      },
      "outputs": [],
      "source": [
        "labels= df_lstm.folder\n",
        "content = df_lstm.Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RrbDHqC5OLqy",
        "outputId": "143bc5c0-7c5d-4a86-f45d-87d2dd485211"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(pandas.core.series.Series, 204850, pandas.core.series.Series, 204850)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "type(labels), len(labels), type(content), len(content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dupb3hGzTLKp",
        "outputId": "ab605ebd-89f1-4ff0-ed15-875e6033a569"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1328"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "len(labels.unique())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBumyr4Uszre"
      },
      "source": [
        "##**4.0 Prepare a word index, dictionary**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-UidBXu-Xep",
        "outputId": "3841eda6-cedb-435a-92ea-b788ecd4a45e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15147377 465523\n"
          ]
        }
      ],
      "source": [
        "word2idx= {}\n",
        "idx = 0\n",
        "n_l = []\n",
        "news_len =0\n",
        "i=0\n",
        "\n",
        "for item in content:\n",
        "  word_list = word_tokenize(str(item))\n",
        "  n_l.append(len(word_list))\n",
        "  for word in word_list:\n",
        "    i+=1\n",
        "    if word not in word2idx:\n",
        "      word2idx[word]= idx\n",
        "      idx += 1\n",
        "      \n",
        "print (i, idx)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_addl.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plSgJOfpOi-S",
        "outputId": "be621783-6dfe-40ba-a401-a2da7bd9f818"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(204850, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dQWidJbtteFf"
      },
      "outputs": [],
      "source": [
        "max_len_article = max(n_l)\n",
        "no_of_articles= len(content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_TtNcmPqt77W",
        "outputId": "dce45a4d-e72d-47c9-aa39-2daa39f09559"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(204850, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "dataset = np.zeros((no_of_articles, 100), dtype= int)\n",
        "dataset.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k1YWUkzzvGO2"
      },
      "outputs": [],
      "source": [
        "i=0\n",
        "idx_list=[]\n",
        "for item in content:\n",
        "  word_list= word_tokenize(str(item))\n",
        "  for token in word_list:\n",
        "    if word2idx.get(token) is not None:\n",
        "      idx = word2idx.get(token)\n",
        "    else:\n",
        "      idx= 0\n",
        "    idx_list.append(idx)\n",
        "  pad_list = [0]*(max_len_article- len(idx_list))\n",
        "  idx_list = idx_list + pad_list\n",
        "  dataset[i]= idx_list[0:100]\n",
        "  idx_list=[]\n",
        "  i+=1\n",
        " \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lQlaf4XmbVfJ"
      },
      "outputs": [],
      "source": [
        "dataset= torch.tensor(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kP2jNA2qbHDr",
        "outputId": "32e8e94f-16d9-4f99-a9c6-b9d312decfbf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([204850, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "dataset.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "az_fGfIPCYSW"
      },
      "source": [
        "####**5.0 DownLoad the pretrained vectors**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKXjSKIgCXlB",
        "outputId": "36fc1b14-7534-417b-89ac-ac435afb5873"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-02-08 16:09:15--  https://dl.fbaipublicfiles.com/fasttext/vectors-english/crawl-300d-2M.vec.zip\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 172.67.9.4, 104.22.75.142, 104.22.74.142, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|172.67.9.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1523785255 (1.4G) [application/zip]\n",
            "Saving to: ‘fastText/crawl-300d-2M.vec.zip’\n",
            "\n",
            "crawl-300d-2M.vec.z 100%[===================>]   1.42G  20.1MB/s    in 74s     \n",
            "\n",
            "2022-02-08 16:10:31 (19.5 MB/s) - ‘fastText/crawl-300d-2M.vec.zip’ saved [1523785255/1523785255]\n",
            "\n",
            "Archive:  fastText/crawl-300d-2M.vec.zip\n",
            "  inflating: fastText/crawl-300d-2M.vec  \n"
          ]
        }
      ],
      "source": [
        "URL = \"https://dl.fbaipublicfiles.com/fasttext/vectors-english/crawl-300d-2M.vec.zip\"\n",
        "FILE = \"fastText\"\n",
        "!wget -P $FILE $URL\n",
        "!unzip $FILE/crawl-300d-2M.vec.zip -d $FILE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dM9k33G2D1Lq"
      },
      "source": [
        "###**6.0 Load the pre-trained vectors and create the embedding matrix**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "76xyIra75_dP"
      },
      "outputs": [],
      "source": [
        "fin = open('/content/fastText/crawl-300d-2M.vec', 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
        "n, d = map(int, fin.readline().split())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JF1fB4Up1t7x",
        "outputId": "86ea5348-59c1-44f7-aaf5-edfaf767f3ff"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "465523"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "len(word2idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JAqpB50VF_4d"
      },
      "outputs": [],
      "source": [
        "embeddings = np.random.uniform(-0.25, 0.25, (len(word2idx), d))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GUJQIp4fCtpk"
      },
      "outputs": [],
      "source": [
        "count =0\n",
        "for line in fin:\n",
        "  tokens = line.rstrip().split(' ')\n",
        "  word = tokens[0]\n",
        "  if word in word2idx:\n",
        "    embeddings[word2idx[word]] = np.array(tokens[1:], dtype=np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VnGvFrZ-EzBq"
      },
      "outputs": [],
      "source": [
        "embeddings= torch.tensor(embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EfSylroUKqA0"
      },
      "source": [
        "Now we have an embedding array wich has the vector for each word in our dictionary. Further, we have 'dataset' which gives the word index for each article"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7pwPiJn81q_"
      },
      "source": [
        "###**7.0 Create Pytorch Dataloaders**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ja01f73FLrBO"
      },
      "outputs": [],
      "source": [
        "labels, uniques = pd.factorize(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLYT5z14IKDk",
        "outputId": "15f86420-85d5-476a-f9c2-93f6f4b217e8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1328"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "len(np.unique(labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mQPqI2dpzaUe"
      },
      "outputs": [],
      "source": [
        "labels = torch.from_numpy(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1oWhDO5qzyTH",
        "outputId": "5889ac9a-7d06-4dd0-bb06-5f523405089a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([204850, 100]), torch.Size([204850]))"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "dataset.shape, labels.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2dZtFV1xsMG1"
      },
      "outputs": [],
      "source": [
        "dataset_= df_lstm.drop(['Text', 'folder'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufgd0eahVVgh",
        "outputId": "5389c385-f7f1-4e6c-e605-d4e3064f315f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Tensor, pandas.core.frame.DataFrame)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "type(dataset), type(dataset_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_v_sNBLoVs6h"
      },
      "outputs": [],
      "source": [
        "dataset= torch.Tensor(dataset_.values)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_addl= torch.Tensor(df_addl)"
      ],
      "metadata": {
        "id": "SHXbiRYcQG6i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(df_addl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4bJYxcaQkI0",
        "outputId": "04cec9de-1100-47ec-803a-0f1bf50c06ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.shape, labels.shape, df_addl.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlVas1mfu27M",
        "outputId": "afe62d93-cdd2-4a8c-e346-6a6a8decad83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([204850, 5]), torch.Size([204850]), torch.Size([204850, 5]))"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QSRzd-a4_Rov"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Train Test Split\n",
        "train_inputs, val_inputs, train_labels, val_labels, train_addl, val_addl = train_test_split(dataset, labels, df_addl, test_size=0.1, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWCS3v_bwRRh",
        "outputId": "f92a1ee1-c20a-40bb-d031-d3c7873be999"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(184365, 20485, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "len(train_inputs), len(val_inputs), type(train_inputs), type (val_inputs), type(dataset), type(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GElTJZYANoYd"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import (TensorDataset, DataLoader, RandomSampler,\n",
        "                              SequentialSampler)\n",
        "\n",
        "\n",
        "batch_size=100\n",
        "\n",
        "# Create DataLoader for training data\n",
        "train_data = TensorDataset(train_inputs, train_addl, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create DataLoader for validation data\n",
        "val_data = TensorDataset(val_inputs, val_addl, val_labels)\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=300)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5nHWuIP0TYg"
      },
      "source": [
        "##**8.Device**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "282xUtFF2MEN",
        "outputId": "c4811d5e-bc7c-47b1-e454-58f82df4cae7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "Device name: Tesla K80\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():       \n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
        "    print('Device name:', torch.cuda.get_device_name(0))\n",
        "\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHUvLUhOCdTf",
        "outputId": "a0bb4938-32cf-4142-817f-c2da818a7596"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1328"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "len (labels.unique())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlyHEG4XPmFB"
      },
      "source": [
        "##**8. LSTM Model Architecture**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "flKn6j0RPa4y"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UkPC7E1srblJ"
      },
      "outputs": [],
      "source": [
        "class LSTM(nn.Module):\n",
        "  def __init__(self,\n",
        "               pretrained_embedding,\n",
        "               ):\n",
        "\n",
        "      super(LSTM, self).__init__()\n",
        "      self.embedding = nn.Embedding.from_pretrained(pretrained_embedding, freeze=False)\n",
        "\n",
        "      self.lstm= nn.LSTM(input_size= 300, hidden_size= 1600, num_layers=2, batch_first= True)\n",
        "\n",
        "      self.fc1 = nn.Linear(1605, 1200)\n",
        "      self.fc2 = nn.Linear(1200, len(labels.unique()))\n",
        "              \n",
        "    \n",
        "  def forward(self, dataset, addl_features):\n",
        "\n",
        "    x_embed = self.embedding(dataset).float()\n",
        "    x, _ = self.lstm(x_embed)\n",
        "    x = x[:, -1, :]\n",
        "    x = torch.cat((x, addl_features), -1)\n",
        "    x = self.fc1(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.fc2(x)\n",
        "    \n",
        "    logits = x\n",
        "    \n",
        "    return logits\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6PRJFIDVAmG"
      },
      "source": [
        "##**9. Instatiate the CNN Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHQHMQmM0LT4",
        "outputId": "0bdf6d01-9971-417d-d78e-23eb513898b4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTM(\n",
              "  (embedding): Embedding(465523, 300)\n",
              "  (lstm): LSTM(300, 1600, num_layers=2, batch_first=True)\n",
              "  (fc1): Linear(in_features=1605, out_features=1200, bias=True)\n",
              "  (fc2): Linear(in_features=1200, out_features=1328, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "model = LSTM(embeddings)\n",
        "model = model.to(device)\n",
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQcIqcvTT86_"
      },
      "source": [
        "##**9.  Optimizer and Loss Function**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a1hOPqFf1oNv"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Instantiate Adadelta optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=.01)\n",
        "#optimizer = torch.optim.SGD(model.parameters(), lr = 0.01)\n",
        "criterion = torch.nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7LtPbo9_qMQ"
      },
      "source": [
        "##**10. Train**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8OOXvsX_ofN",
        "outputId": "b75b9c52-46a0-4ba9-8554-686d0f5a1aeb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1, Train Loss:0.022656 Train Accuracy: 49.86\n",
            "epoch: 2, Train Loss:0.017321 Train Accuracy: 61.28\n",
            "epoch: 3, Train Loss:0.016665 Train Accuracy: 61.81\n",
            "epoch: 4, Train Loss:0.015844 Train Accuracy: 63.19\n",
            "epoch: 5, Train Loss:0.015423 Train Accuracy: 63.89\n",
            "epoch: 6, Train Loss:0.015252 Train Accuracy: 64.04\n",
            "epoch: 7, Train Loss:0.015142 Train Accuracy: 64.12\n",
            "epoch: 8, Train Loss:0.015042 Train Accuracy: 64.24\n",
            "epoch: 9, Train Loss:0.014849 Train Accuracy: 64.68\n",
            "epoch: 10, Train Loss:0.014896 Train Accuracy: 64.40\n"
          ]
        }
      ],
      "source": [
        "# No of Epochs\n",
        "epoch = 10\n",
        "\n",
        "# keeping the network in train mode\n",
        "model.train()\n",
        "train_losses,  train_accuracy = [], []\n",
        "\n",
        "# Loop for no of epochs\n",
        "for e in range(epoch):\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    # Iterate through all the batches in each epoch\n",
        "    i=0\n",
        "    for inputs, addl_inputs, labels in train_dataloader:\n",
        "      i+=1\n",
        "      # Convert the image and label to gpu for faster execution\n",
        "      inputs = inputs.to(device).to(torch.int64)\n",
        "      addl_inputs= addl_inputs.to(device).to(torch.int64)\n",
        "       \n",
        "      labels = labels.to(device)\n",
        "          \n",
        "      # Zero the parameter gradients\n",
        "      optimizer.zero_grad()\n",
        "      \n",
        "      # Passing the data to the model (Forward Pass)\n",
        "      outputs = model(inputs, addl_inputs)\n",
        "\n",
        "                \n",
        "      # Calculating the loss\n",
        "      loss = criterion(outputs, labels)\n",
        "      train_loss += loss.item()\n",
        "\n",
        "      # Performing backward pass (Backpropagation)\n",
        "      loss.backward()\n",
        "\n",
        "      # optimizer.step() updates the weights accordingly\n",
        "      optimizer.step()\n",
        "\n",
        "      _, predicted = torch.max(outputs, 1)\n",
        "      correct += (predicted == labels).sum().item()\n",
        "      #print(i, ')', loss.item(), (predicted == labels).sum().item())\n",
        "      \n",
        "     \n",
        "    # Accuracy calculation\n",
        "    \n",
        "    train_losses.append(train_loss/len (train_data))\n",
        "    train_accuracy.append(100 * correct/len(train_data))\n",
        "    print('epoch: {}, Train Loss:{:.6f} Train Accuracy: {:.2f}'.format(e+1,train_losses[-1], train_accuracy[-1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tO94CX49beIX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af52e1ad-6559-4ade-c9f6-0d1b313ec9ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'> torch.Size([300, 1328])\n",
            "<class 'torch.Tensor'> torch.Size([300, 1328])\n",
            "<class 'torch.Tensor'> torch.Size([300, 1328])\n",
            "<class 'torch.Tensor'> torch.Size([300, 1328])\n",
            "<class 'torch.Tensor'> torch.Size([300, 1328])\n",
            "<class 'torch.Tensor'> torch.Size([300, 1328])\n",
            "<class 'torch.Tensor'> torch.Size([300, 1328])\n",
            "<class 'torch.Tensor'> torch.Size([300, 1328])\n",
            "<class 'torch.Tensor'> torch.Size([300, 1328])\n",
            "<class 'torch.Tensor'> torch.Size([300, 1328])\n",
            "<class 'torch.Tensor'> torch.Size([300, 1328])\n",
            "<class 'torch.Tensor'> torch.Size([300, 1328])\n",
            "<class 'torch.Tensor'> torch.Size([300, 1328])\n",
            "<class 'torch.Tensor'> torch.Size([300, 1328])\n",
            "<class 'torch.Tensor'> torch.Size([300, 1328])\n",
            "<class 'torch.Tensor'> torch.Size([300, 1328])\n",
            "<class 'torch.Tensor'> torch.Size([300, 1328])\n",
            "<class 'torch.Tensor'> torch.Size([300, 1328])\n",
            "<class 'torch.Tensor'> torch.Size([300, 1328])\n",
            "<class 'torch.Tensor'> torch.Size([300, 1328])\n",
            "<class 'torch.Tensor'> torch.Size([300, 1328])\n",
            "<class 'torch.Tensor'> torch.Size([300, 1328])\n",
            "<class 'torch.Tensor'> torch.Size([300, 1328])\n",
            "<class 'torch.Tensor'> torch.Size([300, 1328])\n",
            "<class 'torch.Tensor'> torch.Size([300, 1328])\n",
            "<class 'torch.Tensor'> torch.Size([300, 1328])\n",
            "<class 'torch.Tensor'> torch.Size([300, 1328])\n",
            "<class 'torch.Tensor'> torch.Size([300, 1328])\n",
            "<class 'torch.Tensor'> torch.Size([300, 1328])\n",
            "<class 'torch.Tensor'> torch.Size([300, 1328])\n",
            "<class 'torch.Tensor'> torch.Size([300, 1328])\n",
            "<class 'torch.Tensor'> torch.Size([300, 1328])\n",
            "<class 'torch.Tensor'> torch.Size([300, 1328])\n",
            "<class 'torch.Tensor'> torch.Size([300, 1328])\n",
            "<class 'torch.Tensor'> torch.Size([300, 1328])\n",
            "<class 'torch.Tensor'> torch.Size([300, 1328])\n",
            "<class 'torch.Tensor'> torch.Size([300, 1328])\n",
            "<class 'torch.Tensor'> torch.Size([300, 1328])\n",
            "<class 'torch.Tensor'> torch.Size([300, 1328])\n",
            "<class 'torch.Tensor'> torch.Size([300, 1328])\n",
            "<class 'torch.Tensor'> torch.Size([300, 1328])\n",
            "<class 'torch.Tensor'> torch.Size([300, 1328])\n",
            "<class 'torch.Tensor'> torch.Size([300, 1328])\n",
            "<class 'torch.Tensor'> torch.Size([300, 1328])\n",
            "<class 'torch.Tensor'> torch.Size([300, 1328])\n",
            "<class 'torch.Tensor'> torch.Size([300, 1328])\n",
            "<class 'torch.Tensor'> torch.Size([300, 1328])\n",
            "<class 'torch.Tensor'> torch.Size([300, 1328])\n",
            "<class 'torch.Tensor'> torch.Size([300, 1328])\n",
            "<class 'torch.Tensor'> torch.Size([300, 1328])\n",
            "<class 'torch.Tensor'> torch.Size([300, 1328])\n",
            "<class 'torch.Tensor'> torch.Size([300, 1328])\n",
            "<class 'torch.Tensor'> torch.Size([300, 1328])\n",
            "<class 'torch.Tensor'> torch.Size([300, 1328])\n",
            "<class 'torch.Tensor'> torch.Size([300, 1328])\n",
            "<class 'torch.Tensor'> torch.Size([300, 1328])\n",
            "<class 'torch.Tensor'> torch.Size([300, 1328])\n",
            "<class 'torch.Tensor'> torch.Size([300, 1328])\n",
            "<class 'torch.Tensor'> torch.Size([300, 1328])\n",
            "<class 'torch.Tensor'> torch.Size([300, 1328])\n",
            "<class 'torch.Tensor'> torch.Size([300, 1328])\n",
            "<class 'torch.Tensor'> torch.Size([300, 1328])\n",
            "<class 'torch.Tensor'> torch.Size([300, 1328])\n",
            "<class 'torch.Tensor'> torch.Size([300, 1328])\n",
            "<class 'torch.Tensor'> torch.Size([300, 1328])\n",
            "<class 'torch.Tensor'> torch.Size([300, 1328])\n",
            "<class 'torch.Tensor'> torch.Size([300, 1328])\n",
            "<class 'torch.Tensor'> torch.Size([300, 1328])\n",
            "<class 'torch.Tensor'> torch.Size([85, 1328])\n",
            "1.5570946102556975 62.88689968741121\n"
          ]
        }
      ],
      "source": [
        "\n",
        "eval_model = model\n",
        "eval_model.eval\n",
        "val_accuracy = []\n",
        "val_loss = []\n",
        "\n",
        "for inputs, addl_inputs, labels in val_dataloader:\n",
        "  inputs = inputs.to(device).to(torch.int64)\n",
        "  addl_inputs= addl_inputs.to(device).to(torch.int64)\n",
        "  labels = labels.to(device)\n",
        "  logits = eval_model(inputs, addl_inputs)\n",
        "  print(type(logits), logits.shape)\n",
        "\n",
        "  loss = criterion (logits, labels)\n",
        "  val_loss.append(loss.item())\n",
        "  _, predicted = torch.max(logits, 1)\n",
        "\n",
        "    \n",
        "  accuracy = (predicted == labels).cpu().numpy().mean() * 100\n",
        "\n",
        "  val_accuracy.append(accuracy)\n",
        "\n",
        "val_loss = np.mean(val_loss)\n",
        "val_accuracy = np.mean(val_accuracy)\n",
        "\n",
        "print (val_loss, val_accuracy)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "LSTM_Enron_final.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}